{
	"version": "2.0.0",
	"tasks": [
		{
			"label": "Create Types of AI post",
			"type": "shell",
			"command": "touch src/content/docs/introduction/types-of-ai.md"
		},
		{
			"label": "Populate Types of AI post",
			"type": "shell",
			"command": "cat <<EOF > src/content/docs/introduction/types-of-ai.md\n---\ntitle: Types of AI\ndescription: Understanding the different classifications of Artificial Intelligence.\n---\n\nArtificial Intelligence can be classified in several ways, often based on its capabilities (Type 1) or its functionality (Type 2).\n\n## Type 1: Based on Capabilities\n\nThis classification focuses on how well AI can perform tasks compared to human intelligence.\n\n### 1. Artificial Narrow Intelligence (ANI)\nAlso known as \"Weak AI,\" ANI is designed to perform a specific task (e.g., facial recognition, voice assistants, or playing chess). All current AI systems, including LLMs like ChatGPT, are considered Narrow AI because they operate within a limited context.\n\n### 2. Artificial General Intelligence (AGI)\nAlso known as \"Strong AI,\" AGI refers to a machine that possesses the ability to understand, learn, and apply knowledge in a way that is indistinguishable from a human across any intellectual task. AGI does not yet exist.\n\n### 3. Artificial Super Intelligence (ASI)\nASI is a hypothetical level of AI that surpasses human intelligence across all fields, including creativity, general wisdom, and social skills.\n\n## Type 2: Based on Functionality\n\nProposed by Arend Hintze, this classification looks at how the AI processes information.\n\n- **Reactive Machines:** The simplest form of AI. They do not store memories or use past experiences to inform future actions (e.g., IBM's Deep Blue).\n- **Limited Memory:** AI that can look into the past to make better decisions. Most modern AI, including self-driving cars and chatbots, falls into this category.\n- **Theory of Mind:** A hypothetical type of AI that can understand human emotions, beliefs, and intentions.\n- **Self-Aware AI:** The ultimate stage of AI development where the machine has its own consciousness and self-awareness. This remains purely speculative.\nEOF\n"
		},
		{
			"label": "Update Introduction index with Types of AI link",
			"type": "shell",
			"command": "cat <<EOF > src/content/docs/introduction/index.md\n---\ntitle: Introduction to AI\ndescription: Start your journey here. Learn what Artificial Intelligence is, its history, and its core concepts.\n---\n\nWelcome to the Introduction to AI section. This is the perfect place to start if you are new to Artificial Intelligence.\n\n## Topics\n\n- [What is AI?](/introduction/what-is-ai)\n- [History of AI](/introduction/history-of-ai)\n- [Types of AI](/introduction/types-of-ai)\nEOF\n"
		},
		{
			"label": "Populate AI Ethics and Safety post",
			"type": "shell",
			"command": "cat <<EOF > src/content/docs/introduction/ai-ethics-and-safety.md\n---\ntitle: AI Ethics and Safety\ndescription: Understanding the ethical challenges and safety concerns in AI development.\n---\n\nAs Artificial Intelligence becomes more integrated into our daily lives, understanding its ethical implications and safety requirements is crucial. AI systems are powerful tools, but they can also cause harm if not designed and deployed responsibly.\n\n## Why Ethics Matter in AI?\n\nAI systems make decisions that affect real people—hiring processes, loan approvals, medical diagnoses, and criminal justice sentencing. If these systems are flawed, they can perpetuate discrimination and injustice at scale.\n\n## Key Ethical Principles\n\n### 1. Bias and Fairness\nAI models are trained on historical data, which often contains human biases. If the training data is biased, the AI will learn and amplify those biases.\n- **Example:** A hiring algorithm trained on past resumes (mostly from men) might penalize resumes from women.\n- **Goal:** Ensure AI systems treat all demographic groups fairly.\n\n### 2. Transparency and Explainability (XAI)\nMany modern AI models, especially Deep Learning networks, operate as \"black boxes.\" It is often difficult to understand *why* a model made a specific decision.\n- **Challenge:** If a loan application is rejected by an AI, the applicant deserves to know the reason.\n- **Goal:** Develop \"Explainable AI\" (XAI) that provides understandable reasons for its outputs.\n\n### 3. Privacy and Data Protection\nAI systems require massive amounts of data, often including personal information.\n- **Risk:** Models can inadvertently memorize and leak sensitive user data.\n- **Goal:** Implement techniques like Differential Privacy and Federated Learning to protect user data.\n\n### 4. Accountability\nWhen an AI system makes a mistake (e.g., a self-driving car accident), who is responsible? The developer? The user? The manufacturer?\n- **Goal:** Establish clear lines of responsibility and governance frameworks.\n\n## AI Safety\n\nAI Safety focuses on ensuring that AI systems operate reliably and do not cause unintended harm.\n\n- **Robustness:** AI should function correctly even when faced with unexpected inputs or adversarial attacks.\n- **Alignment:** AI goals must align with human values. A system optimized purely for a metric (e.g., \"maximize engagement\") might cause harm (e.g., promoting polarizing content) to achieve that goal.\n\n## The Future: Responsible AI\n\nGovernments and organizations worldwide are developing guidelines for \"Responsible AI.\" This involves a lifecycle approach where ethical considerations are integrated from the design phase through to deployment and monitoring.\nEOF\n",
			"group": "build"
		},
		{
			"label": "Fix AI Ethics and Safety post formatting",
			"type": "shell",
			"command": "cat <<EOF > src/content/docs/introduction/ai-ethics-and-safety.md\n---\ntitle: AI Ethics and Safety\ndescription: Understanding the ethical challenges and safety concerns in AI development.\n---\n\nAs Artificial Intelligence becomes more integrated into our daily lives, understanding its ethical implications and safety requirements is crucial. AI systems are powerful tools, but they can also cause harm if not designed and deployed responsibly.\n\n## Why Ethics Matter in AI?\n\nAI systems make decisions that affect real people—hiring processes, loan approvals, medical diagnoses, and criminal justice sentencing. If these systems are flawed, they can perpetuate discrimination and injustice at scale.\n\n## Key Ethical Principles\n\n### 1. Bias and Fairness\n\nAI models are trained on historical data, which often contains human biases. If the training data is biased, the AI will learn and amplify those biases.\n\n- **Example:** A hiring algorithm trained on past resumes (mostly from men) might penalize resumes from women.\n- **Goal:** Ensure AI systems treat all demographic groups fairly.\n\n### 2. Transparency and Explainability (XAI)\n\nMany modern AI models, especially Deep Learning networks, operate as \"black boxes.\" It is often difficult to understand *why* a model made a specific decision.\n\n- **Challenge:** If a loan application is rejected by an AI, the applicant deserves to know the reason.\n- **Goal:** Develop \"Explainable AI\" (XAI) that provides understandable reasons for its outputs.\n\n### 3. Privacy and Data Protection\n\nAI systems require massive amounts of data, often including personal information.\n\n- **Risk:** Models can inadvertently memorize and leak sensitive user data.\n- **Goal:** Implement techniques like Differential Privacy and Federated Learning to protect user data.\n\n### 4. Accountability\n\nWhen an AI system makes a mistake (e.g., a self-driving car accident), who is responsible? The developer? The user? The manufacturer?\n\n- **Goal:** Establish clear lines of responsibility and governance frameworks.\n\n## AI Safety\n\nAI Safety focuses on ensuring that AI systems operate reliably and do not cause unintended harm.\n\n- **Robustness:** AI should function correctly even when faced with unexpected inputs or adversarial attacks.\n- **Alignment:** AI goals must align with human values. A system optimized purely for a metric (e.g., \"maximize engagement\") might cause harm (e.g., promoting polarizing content) to achieve that goal.\n\n## The Future: Responsible AI\n\nGovernments and organizations worldwide are developing guidelines for \"Responsible AI.\" This involves a lifecycle approach where ethical considerations are integrated from the design phase through to deployment and monitoring.\nEOF\n",
			"group": "build"
		}
	]
}